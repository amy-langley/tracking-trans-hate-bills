{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efc0ead-b510-4cfa-8c0e-5ef00f31966a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from nltk import ngrams, FreqDist, word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os.path\n",
    "from pprint import pprint\n",
    "\n",
    "from lib.language import get_wordnet_pos, clean_tokens, tokenize_file\n",
    "from lib.legiscan import summarize_metadata_file\n",
    "from lib.util import load_json, write_json\n",
    "\n",
    "\n",
    "BillFiles = namedtuple(\"BillFiles\", \"bill_id contents_path meta_path\")\n",
    "\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "whitelist = load_json('../configuration/custom_whitelist.json')\n",
    "\n",
    "stopwords = set(\n",
    "    word\n",
    "    for word in\n",
    "    chain.from_iterable([\n",
    "        load_json('../artifacts/legal_stopwords.json'),\n",
    "        load_json('../configuration/custom_stopwords.json'),\n",
    "    ])\n",
    "    if word not in whitelist\n",
    ")\n",
    "\n",
    "def generate_document_tokens(path, output_path):\n",
    "    files = glob(path)\n",
    "    bill_files = [\n",
    "        BillFiles(\n",
    "            os.path.splitext(os.path.basename(file))[0], \n",
    "            file,\n",
    "            f'../tmp/legiscan/bill_meta_{os.path.splitext(os.path.basename(file))[0]}.json',\n",
    "        )\n",
    "        for file \n",
    "        in files\n",
    "    ]\n",
    "\n",
    "    document_tokens = [\n",
    "        (\n",
    "            bill_file, \n",
    "            summarize_metadata_file(bill_file.meta_path), \n",
    "            list(tokenize_file(bill_file.contents_path))\n",
    "        )\n",
    "        for bill_file\n",
    "        in bill_files\n",
    "        if os.path.exists(bill_file.meta_path)\n",
    "    ]\n",
    "\n",
    "    write_json(document_tokens, output_path)\n",
    "    return document_tokens\n",
    "\n",
    "def explode_ngrams(doc_tokens, ngram_length):\n",
    "    return [\n",
    "        (bill_file, summary, list(ngrams(tokens, ngram_length)))\n",
    "        for bill_file, summary, tokens\n",
    "        in doc_tokens\n",
    "    ]\n",
    "\n",
    "try:\n",
    "    document_tokens = document_tokens\n",
    "except:\n",
    "    document_tokens = generate_document_tokens('../bills/*', '../tmp/document_tokens.json')\n",
    "\n",
    "GRAM_LENGTH = 10\n",
    "corpus = {}\n",
    "exploded = explode_ngrams(document_tokens, GRAM_LENGTH)\n",
    "for exploder in exploded:\n",
    "    bill_file, summary, grams = exploder\n",
    "    for gram in grams:\n",
    "        arr = corpus.get(gram, [])\n",
    "        corpus[gram] = [*arr, (bill_file, summary)]\n",
    "\n",
    "write_json({\n",
    "    ' '.join(k): [v[1]['state'] + ' ' + v[1]['bill_id'] + ': ' + ', '.join(v[1]['sponsors']) for v in vv]\n",
    "    for k, vv\n",
    "    in corpus.items()\n",
    "    if len(vv) > 20\n",
    "}, f'../tmp/grams-{str(GRAM_LENGTH).zfill(2)}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbd4fa50-4f7d-4b73-a109-2dc6211c3627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amy/Library/Caches/pypoetry/virtualenvs/tthb-IZuJWOhf-py3.9/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:189: RuntimeWarning: invalid value encountered in cast\n",
      "  return values.astype(dtype, copy=copy)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>occurrences</th>\n",
       "      <th>improbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stop luteinizing hormone secretion and therefore testosterone secretion or synthetic</td>\n",
       "      <td>21</td>\n",
       "      <td>4.712104e+25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>male patient such a augmentation mammoplasty facial feminization surgery liposuction</td>\n",
       "      <td>25</td>\n",
       "      <td>3.855693e+25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>individual do not have normal sex chromosome structure sex steroid</td>\n",
       "      <td>29</td>\n",
       "      <td>1.158572e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>physiological or anatomical characteristic that resemble a sex different from</td>\n",
       "      <td>61</td>\n",
       "      <td>1.394117e+19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>external biological sex characteristic that be irresolvably ambiguous such a</td>\n",
       "      <td>55</td>\n",
       "      <td>5.772981e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>production of estrogen and progesterone when use to delay or</td>\n",
       "      <td>28</td>\n",
       "      <td>7.494855e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>of parent to direct the upbringing education health care and</td>\n",
       "      <td>33</td>\n",
       "      <td>3.990044e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>for related purpose be it enact by the legislature of</td>\n",
       "      <td>25</td>\n",
       "      <td>4.568249e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>for the purpose of attempt to alter the appearance of</td>\n",
       "      <td>34</td>\n",
       "      <td>3.010210e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>the general assembly of the state of missouri a follow</td>\n",
       "      <td>43</td>\n",
       "      <td>7.807533e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                   phrase  \\\n",
       "24   stop luteinizing hormone secretion and therefore testosterone secretion or synthetic   \n",
       "25   male patient such a augmentation mammoplasty facial feminization surgery liposuction   \n",
       "117                    individual do not have normal sex chromosome structure sex steroid   \n",
       "151         physiological or anatomical characteristic that resemble a sex different from   \n",
       "166          external biological sex characteristic that be irresolvably ambiguous such a   \n",
       "268                          production of estrogen and progesterone when use to delay or   \n",
       "592                          of parent to direct the upbringing education health care and   \n",
       "647                                 for related purpose be it enact by the legislature of   \n",
       "656                                 for the purpose of attempt to alter the appearance of   \n",
       "719                                the general assembly of the state of missouri a follow   \n",
       "\n",
       "     occurrences  improbability  \n",
       "24            21   4.712104e+25  \n",
       "25            25   3.855693e+25  \n",
       "117           29   1.158572e+20  \n",
       "151           61   1.394117e+19  \n",
       "166           55   5.772981e+18  \n",
       "268           28   7.494855e+16  \n",
       "592           33   3.990044e+12  \n",
       "647           25   4.568249e+11  \n",
       "656           34   3.010210e+11  \n",
       "719           43   7.807533e+09  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "df = pd.read_json('../tmp/prob_sorted_ngrams.json')\n",
    "df.columns = ['phrase', 'occurrences', 'improbability']\n",
    "sliced = df.sample(n=10)\n",
    "sliced.sort_values(by='improbability', ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
