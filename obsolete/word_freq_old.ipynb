{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97521a8a-f316-4a1d-8434-1d76a22c794e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "import glob\n",
    "from itertools import islice\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PyPDF2 import PdfReader\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Define a function to plot word cloud\n",
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "def extract_html_file(file_path: str):\n",
    "    soup = None\n",
    "    with open(file_path, 'r') as f:\n",
    "        soup = Soup(f, 'html.parser')\n",
    "\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "\n",
    "    text = soup.get_text()\n",
    "    # break into lines and remove leading and trailing space on each\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    # break multi-headlines into a line each\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    # drop blank lines\n",
    "    text = \"\\n\".join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "    return text\n",
    "\n",
    "def extract_pdf_file(file_path: str):\n",
    "    text = ''\n",
    "    reader = PdfReader(file_path)\n",
    "    for page in reader.pages:\n",
    "        text = text + \"\\n\" + page.extract_text()\n",
    "        \n",
    "    return text\n",
    "\n",
    "corpus = ''\n",
    "\n",
    "for file in glob.glob('bills/*.html'):\n",
    "    try:\n",
    "        corpus = corpus + \"\\n\" + extract_html_file(file)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to extract text from {file}: {e}')\n",
    "\n",
    "for file in glob.glob('bills/*.pdf'):\n",
    "    try:\n",
    "        corpus = corpus + \"\\n\" + extract_pdf_file(file)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to extract text from {file}: {e}')\n",
    "    \n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac9b37-7bda-4fa3-8201-cadbe7c29e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = corpus.lower()\n",
    "\n",
    "custom_stopwords = []\n",
    "with open('custom_stopwords.json', 'r') as f:\n",
    "    custom_stopwords = json.load(f)\n",
    "\n",
    "STOPWORDS.update(custom_stopwords)\n",
    "\n",
    "#supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', \n",
    "# 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', \n",
    "# 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', \n",
    "# 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', \n",
    "# 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', \n",
    "# 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', \n",
    "# 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', \n",
    "# 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', \n",
    "# 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', \n",
    "# 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', \n",
    "# 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', \n",
    "# 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', \n",
    "# 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r'\n",
    "\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(\n",
    "    width=1920, \n",
    "    height=1080,\n",
    "    random_state=2, \n",
    "    background_color='white', \n",
    "    colormap='viridis', \n",
    "    collocations=True,\n",
    "    collocation_threshold=50,\n",
    "    stopwords=STOPWORDS,\n",
    "    max_words=1000,\n",
    "    min_word_length=4,\n",
    "    max_font_size=200,\n",
    "    min_font_size=10,\n",
    "    relative_scaling=0.8,\n",
    "    prefer_horizontal=0.7,\n",
    ")\n",
    "\n",
    "wordcloud_plot = wordcloud.generate(corpus)\n",
    "\n",
    "# Plot\n",
    "wordcloud_plot.to_file('cloud.png')\n",
    "plot_cloud(wordcloud_plot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
