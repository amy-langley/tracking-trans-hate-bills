{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c35219-04ce-4574-99a5-d31ae0a56179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from pprint import pprint\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_pdf_tokens_pypdf2(file_path: str) -> str:\n",
    "    reader = PdfReader(file_path)\n",
    "    return reader.pages[0].extract_text()\n",
    "\n",
    "def extract_pdf_tokens_pdfplumber(file_path: str) -> str:\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        return pdf.pages[0].extract_text()\n",
    "\n",
    "pprint(extract_pdf_tokens_pdfplumber('../archive/bills/OK_SB973.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "156b3a90-0508-4d68-888e-07de4a226682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the quick the \\n brown fox jumps over\\n the \\n lazy dog', 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('o', 'ver')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "\n",
    "def find_hyphenate(text: str):\n",
    "    return re.subn(r'(\\w)+-\\s*\\n\\s*(\\w+)', r'\\g<1>\\g<2>\\n', text, re.MULTILINE)\n",
    "\n",
    "sample = 'the quick the \\n brown fox jumps o- \\n ver the \\n lazy dog'\n",
    "print(find_hyphenate(sample))\n",
    "\n",
    "re.search(r'(\\w)+-\\s*\\n\\s+(\\w+)', sample).groups()\n",
    "# glob('../tmp/neutral_corpus/bills/*.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7688789-a5f5-43f1-b9b5-9e6f6e3a29c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "from collections import namedtuple\n",
    "import json\n",
    "from retrieval.legiscan import legiscan_auth\n",
    "\n",
    "Dataset = namedtuple(\"Dataset\", \"state year session modified exported json csv\")\n",
    "\n",
    "@legiscan_auth\n",
    "def enumerate_datasets(session):\n",
    "    return session.get('https://legiscan.com/datasets').text\n",
    "\n",
    "soup = Soup(enumerate_datasets())\n",
    "dataset_table = soup.find(id='gaits-datasets')\n",
    "table_data = [\n",
    "    Dataset(*(\n",
    "        cell.text if len(cell.find_all('a'))<1 else cell.find_all('a')[0].attrs['href']\n",
    "        for cell \n",
    "        in row.find_all('td')))\n",
    "    for row\n",
    "    in dataset_table.find_all('tbody')[0].find_all('tr')\n",
    "]\n",
    "\n",
    "len([item.json for item in table_data if '2023' in item.session])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c65f9e4-5f48-438f-82ee-e0d208f26e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../datasets/geography.json', 'r') as f:\n",
    "    geography = json.load(f)\n",
    "    \n",
    "pairs = [\n",
    "('ALABAMA', 'AL'),\n",
    "('ALASKA', 'AK'),\n",
    "('AMERICAN SAMOA', 'AS'),\n",
    "('ARIZONA', 'AZ'),\n",
    "('ARKANSAS', 'AR'),\n",
    "('CALIFORNIA', 'CA'),\n",
    "('COLORADO', 'CO'),\n",
    "('CONNECTICUT', 'CT'),\n",
    "('DELAWARE', 'DE'),\n",
    "('DISTRICT OF COLUMBIA', 'DC'),\n",
    "('FLORIDA', 'FL'),\n",
    "('GEORGIA', 'GA'),\n",
    "('GUAM', 'GU'),\n",
    "('HAWAII', 'HI'),\n",
    "('IDAHO', 'ID'),\n",
    "('ILLINOIS', 'IL'),\n",
    "('INDIANA', 'IN'),\n",
    "('IOWA', 'IA'),\n",
    "('KANSAS', 'KS'),\n",
    "('KENTUCKY', 'KY'),\n",
    "('LOUISIANA', 'LA'),\n",
    "('MAINE', 'ME'),\n",
    "('MARYLAND', 'MD'),\n",
    "('MASSACHUSETTS', 'MA'),\n",
    "('MICHIGAN', 'MI'),\n",
    "('MINNESOTA', 'MN'),\n",
    "('MISSISSIPPI', 'MS'),\n",
    "('MISSOURI', 'MO'),\n",
    "('MONTANA', 'MT'),\n",
    "('NEBRASKA', 'NE'),\n",
    "('NEVADA', 'NV'),\n",
    "('NEW HAMPSHIRE', 'NH'),\n",
    "('NEW JERSEY', 'NJ'),\n",
    "('NEW MEXICO', 'NM'),\n",
    "('NEW YORK', 'NY'),\n",
    "('NORTH CAROLINA', 'NC'),\n",
    "('NORTH DAKOTA', 'ND'),\n",
    "('NORTHERN MARIANA IS', 'MP'),\n",
    "('OHIO', 'OH'),\n",
    "('OKLAHOMA', 'OK'),\n",
    "('OREGON', 'OR'),\n",
    "('PENNSYLVANIA', 'PA'),\n",
    "('PUERTO RICO', 'PR'),\n",
    "('RHODE ISLAND', 'RI'),\n",
    "('SOUTH CAROLINA', 'SC'),\n",
    "('SOUTH DAKOTA', 'SD'),\n",
    "('TENNESSEE', 'TN'),\n",
    "('TEXAS', 'TX'),\n",
    "('UNITED STATES', 'US'),\n",
    "('UTAH', 'UT'),\n",
    "('VERMONT', 'VT'),\n",
    "('VIRGINIA', 'VA'),\n",
    "('VIRGIN ISLANDS', 'VI'),\n",
    "('WASHINGTON', 'WA'),\n",
    "('WEST VIRGINIA', 'WV'),\n",
    "('WISCONSIN', 'WI'),\n",
    "('WYOMING', 'WY'),\n",
    "]\n",
    "\n",
    "def fix_case(state: str):\n",
    "    return ' '.join(word.capitalize() for word in state.split(' '))\n",
    "\n",
    "geography['state_abbreviations'] = {fix_case(tup[0]): tup[1] for tup in pairs}\n",
    "geography['state_names'] = {tup[1]: fix_case(tup[0]) for tup in pairs}\n",
    "\n",
    "with open('../datasets/geography.json', 'w') as f:\n",
    "    json.dump(geography, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38e3373d-f7a8-4a36-9d24-d3ac1ebc56a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 'US',\n",
       "  'bill_id': 'HB1112',\n",
       "  'status_date': '2023-02-21',\n",
       "  'legiscan_bill_id': 1717626},\n",
       " {'state': 'OK',\n",
       "  'bill_id': 'SB937',\n",
       "  'status_date': '2023-02-06',\n",
       "  'legiscan_bill_id': 1669660},\n",
       " {'state': 'KS',\n",
       "  'bill_id': 'SB233',\n",
       "  'status_date': '2023-03-01',\n",
       "  'legiscan_bill_id': 1704027},\n",
       " {'state': 'MI',\n",
       "  'bill_id': 'HB4075',\n",
       "  'status_date': '2023-02-07',\n",
       "  'legiscan_bill_id': 1697993},\n",
       " {'state': 'SC',\n",
       "  'bill_id': 'H3801',\n",
       "  'status_date': '2023-01-25',\n",
       "  'legiscan_bill_id': 1679817},\n",
       " {'state': 'AR',\n",
       "  'bill_id': 'SB270',\n",
       "  'status_date': '2023-03-07',\n",
       "  'legiscan_bill_id': 1708046},\n",
       " {'state': 'NM',\n",
       "  'bill_id': 'HM57',\n",
       "  'status_date': '2023-02-17',\n",
       "  'legiscan_bill_id': 1714178},\n",
       " {'state': 'TX',\n",
       "  'bill_id': 'SB437',\n",
       "  'status_date': '2023-01-12',\n",
       "  'legiscan_bill_id': 1657171},\n",
       " {'state': 'PA',\n",
       "  'bill_id': 'HB138',\n",
       "  'status_date': '2023-03-08',\n",
       "  'legiscan_bill_id': 1730236},\n",
       " {'state': 'ID',\n",
       "  'bill_id': 'S1100',\n",
       "  'status_date': '2023-03-09',\n",
       "  'legiscan_bill_id': 1705651},\n",
       " {'state': 'WV',\n",
       "  'bill_id': 'SB517',\n",
       "  'status_date': '2023-01-30',\n",
       "  'legiscan_bill_id': 1685161},\n",
       " {'state': 'NH',\n",
       "  'bill_id': 'HB396',\n",
       "  'status_date': '2023-01-09',\n",
       "  'legiscan_bill_id': 1646387},\n",
       " {'state': 'TX',\n",
       "  'bill_id': 'SB476',\n",
       "  'status_date': '2023-01-17',\n",
       "  'legiscan_bill_id': 1663682},\n",
       " {'state': 'SC',\n",
       "  'bill_id': 'H3728',\n",
       "  'status_date': '2023-02-09',\n",
       "  'legiscan_bill_id': 1665907},\n",
       " {'state': 'SC',\n",
       "  'bill_id': 'S0424',\n",
       "  'status_date': '2023-01-19',\n",
       "  'legiscan_bill_id': 1668734},\n",
       " {'state': 'SC',\n",
       "  'bill_id': 'H3616',\n",
       "  'status_date': '2023-01-11',\n",
       "  'legiscan_bill_id': 1654119},\n",
       " {'state': 'IA',\n",
       "  'bill_id': 'SF129',\n",
       "  'status_date': '2023-01-25',\n",
       "  'legiscan_bill_id': 1679538},\n",
       " {'state': 'ME',\n",
       "  'bill_id': 'LD123',\n",
       "  'status_date': '2023-01-10',\n",
       "  'legiscan_bill_id': 1644150},\n",
       " {'state': 'TX',\n",
       "  'bill_id': 'HB3213',\n",
       "  'status_date': '2023-03-02',\n",
       "  'legiscan_bill_id': 1725102},\n",
       " {'state': 'MN',\n",
       "  'bill_id': 'HF1903',\n",
       "  'status_date': '2023-02-16',\n",
       "  'legiscan_bill_id': 1710675}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from operator import itemgetter\n",
    "import json\n",
    "\n",
    "metas =  glob.glob('../tmp/legiscan/*meta*.json')\n",
    "def get_meta(meta_name):\n",
    "    with open(meta_name, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def summarize(meta):\n",
    "    bill = meta['bill']\n",
    "    state, bill_id, status_date, legiscan_bill_id = itemgetter('state', 'bill_number', 'status_date', 'bill_id')(bill)\n",
    "    \n",
    "    return {\n",
    "        'state': state,\n",
    "        'bill_id': bill_id,\n",
    "        'status_date': status_date,\n",
    "        'legiscan_bill_id': legiscan_bill_id,\n",
    "    }\n",
    "\n",
    "[summarize(get_meta(meta)) for meta in metas][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d658fa8-fb45-41c2-942b-edc122e164ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data \"equalitytexas.json\" refreshed with 139 items (0.16s elapsed)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from itertools import chain, islice, takewhile\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import string\n",
    "import time\n",
    "\n",
    "TRACKER_URL = 'https://www.equalitytexas.org/legislature/legislative-bill-tracker-2023'\n",
    "OUTPUT_PATH = '../datasets/equalitytexas.json'\n",
    "\n",
    "def extract_row(row):\n",
    "    cells = row.find_all('td')\n",
    "    d = re.search(r'\\d{2}/\\d{2}/\\d{4}', cells[3].text)\n",
    "    return {\n",
    "        'state': 'TX',\n",
    "        'bill_id': cells[0].text,\n",
    "        'sponsors': [sponsor for sponsor in cells[1].text.split(' ') if sponsor not in string.punctuation],\n",
    "        'description': cells[2].text,\n",
    "        'status_date': d.group(0) if d else '',\n",
    "    }\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "page = requests.get(TRACKER_URL)\n",
    "\n",
    "soup = Soup(page.content, 'html.parser')\n",
    "bad_bills = soup.find(id='bad-bills')\n",
    "\n",
    "bill_tables = islice(bad_bills.parent.parent.find_all('table'), 1, None)\n",
    "relevant_rows = chain.from_iterable(\n",
    "    (row for row in tbl.find_all('tr') if not row.find('th'))\n",
    "    for tbl\n",
    "    in bill_tables\n",
    ")\n",
    "\n",
    "dataset = list((takewhile(lambda r: r['bill_id'] != '#N/A', (extract_row(row) for row in relevant_rows))))\n",
    "\n",
    "with open(OUTPUT_PATH, 'w') as f:\n",
    "    json.dump(dataset, f, indent=2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Data \"equalitytexas.json\" refreshed with {len(dataset)} items ({(end_time-start_time):.2f}s elapsed)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "add61f42-c18d-46d7-a44b-a4113c3f5c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from itertools import chain\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pyjsparser import parse\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "URL = 'https://tracktranslegislation.com'\n",
    "page = requests.get(URL)\n",
    "soup = Soup(page.content, 'html.parser')\n",
    "script_tags = soup.find_all('script')\n",
    "sources = [source_tag.attrs['src'] for source_tag in soup.find_all('script') if source_tag.has_attr('src')]\n",
    "quarry = urljoin(URL, next(source for source in sources if 'chunks/70-' in source))\n",
    "script_contents = requests.get(quarry).text\n",
    "\n",
    "def find_in_graph(subgraph):\n",
    "    results = []\n",
    "    items = subgraph.values() if isinstance(subgraph, dict) else subgraph\n",
    "    local_results = (item for item in items if isinstance(item, str) and len(item) > 10000)\n",
    "    return (chain.from_iterable([local_results, *(find_in_graph(item) for item in items if isinstance(item, dict) or isinstance(item,list))]))\n",
    "\n",
    "parsed = parse(script_contents)\n",
    "candidates = find_graph(parsed)\n",
    "jsonstr = next(candidates)\n",
    "len(json.loads(jsonstr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1e3d9735-dd29-4e0a-a9ec-8f18ee791954",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 3, 'b')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = ('a', 3)\n",
    "t2 = (*t1, 'b')\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "82488a43-ee59-4e96-83ae-5b677f49a35c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AK', 'HB27', 1646385),\n",
       " ('AK', 'SB96', 1730580),\n",
       " ('AK', 'HB105', 1730818),\n",
       " ('AR', 'HB1156', 1662211),\n",
       " ('AR', 'HB1468', 1715730),\n",
       " ('AR', 'SB125', 1680399),\n",
       " ('AR', 'SB199', 1696352),\n",
       " ('AR', 'SB270', 1708046),\n",
       " ('AR', 'SB43', 1646838),\n",
       " ('AR', 'SB294', 1715618)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain, islice\n",
    "import json\n",
    "\n",
    "mapper = {}\n",
    "with open('resolver_map.json', 'r') as f:\n",
    "    mapper = json.load(f)\n",
    "\n",
    "list(islice(chain.from_iterable(\n",
    "    ((state, k, v) for k, v in m['bills'].items())\n",
    "    for state, m \n",
    "    in mapper.items()\n",
    "), 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1601a-fe14-4330-aad1-9afcbcf53c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea2b3615-7776-475c-b672-21bbfa6ac2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arr': [4],\n",
      " 'bar': {'blah': 'blah'},\n",
      " 'baz': 'baz',\n",
      " 'foo': {'bar': 'bar', 'glarch': 'glarch'}}\n"
     ]
    }
   ],
   "source": [
    "from mergedeep import merge\n",
    "\n",
    "a = {\n",
    "    'foo': {\n",
    "        'bar': 'baz',\n",
    "        'glarch': 'glarch',\n",
    "    },\n",
    "    'bar': 3,\n",
    "    'arr': [3]\n",
    "}\n",
    "\n",
    "b = {\n",
    "    'foo': {\n",
    "        'bar': 'bar',\n",
    "    },\n",
    "    'baz': 'baz',\n",
    "    'bar': {\n",
    "        'blah': 'blah'\n",
    "    },\n",
    "    'arr': [4]\n",
    "}\n",
    "\n",
    "c = {\n",
    "    'foo': { }\n",
    "}\n",
    "\n",
    "dummy = {}\n",
    "merge(dummy, a, b, c)\n",
    "pprint(dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da474ac1-ec67-4292-978c-b09e049c9c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'OK',\n",
       " 'searchresult': {'summary': {'page': '1 of 1',\n",
       "   'range': '1 - 4',\n",
       "   'relevancy': '100% - 91%',\n",
       "   'count': 4,\n",
       "   'page_current': 1,\n",
       "   'page_total': 1,\n",
       "   'query': '(577:(pos=1))'},\n",
       "  '0': {'relevance': 100,\n",
       "   'state': 'ME',\n",
       "   'bill_number': 'LD930',\n",
       "   'bill_id': 1724385,\n",
       "   'change_hash': 'e268ccb1b9c79c60f817f50ca912edd3',\n",
       "   'url': 'https://legiscan.com/ME/bill/LD930/2023',\n",
       "   'text_url': 'https://legiscan.com/ME/text/LD930/2023',\n",
       "   'research_url': 'https://legiscan.com/ME/research/LD930/2023',\n",
       "   'last_action_date': '2023-03-02',\n",
       "   'last_action': 'On motion by Senator Carney of Cumberland, REFERRED to the Committee on Judiciary, in concurrence.',\n",
       "   'title': \"An Act to Allow Only Students of Female Gender to Participate in Women's and Girls' Scholastic Sports\"},\n",
       "  '1': {'relevance': 99,\n",
       "   'state': 'ME',\n",
       "   'bill_number': 'LD577',\n",
       "   'bill_id': 1702330,\n",
       "   'change_hash': '17188394c2eec6b2163091eb1ddda484',\n",
       "   'url': 'https://legiscan.com/ME/bill/LD577/2023',\n",
       "   'text_url': 'https://legiscan.com/ME/text/LD577/2023',\n",
       "   'research_url': 'https://legiscan.com/ME/research/LD577/2023',\n",
       "   'last_action_date': '2023-03-09',\n",
       "   'last_action': 'Work Session Held: TABLED',\n",
       "   'title': 'An Act to Increase Availability of Election Information on Local Government Websites'},\n",
       "  '2': {'relevance': 98,\n",
       "   'state': 'ME',\n",
       "   'bill_number': 'LD736',\n",
       "   'bill_id': 1708418,\n",
       "   'change_hash': 'a681ebe01a6a08118064054564ef7cb5',\n",
       "   'url': 'https://legiscan.com/ME/bill/LD736/2023',\n",
       "   'text_url': 'https://legiscan.com/ME/text/LD736/2023',\n",
       "   'research_url': 'https://legiscan.com/ME/research/LD736/2023',\n",
       "   'last_action_date': '2023-02-16',\n",
       "   'last_action': 'In concurrence. ORDERED SENT FORTHWITH.',\n",
       "   'title': 'An Act to Remove the Requirement That Certain Motor Vehicles Be Equipped with a Front License Plate'},\n",
       "  '3': {'relevance': 91,\n",
       "   'state': 'ME',\n",
       "   'bill_number': 'LD538',\n",
       "   'bill_id': 1699866,\n",
       "   'change_hash': '7343b4eda237e76a261b353726aa1141',\n",
       "   'url': 'https://legiscan.com/ME/bill/LD538/2023',\n",
       "   'text_url': 'https://legiscan.com/ME/text/LD538/2023',\n",
       "   'research_url': 'https://legiscan.com/ME/research/LD538/2023',\n",
       "   'last_action_date': '2023-02-09',\n",
       "   'last_action': 'The Bill was REFERRED to the Committee on JUDICIARY  in concurrence',\n",
       "   'title': 'An Act Regarding the Qualification of Expert Witnesses in Certain Family Court Actions'}}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from legiscan import legiscan_api\n",
    "import requests\n",
    "\n",
    "@legiscan_api\n",
    "def do_search(state: str, term: str, api_key: str):\n",
    "    short_url = 'https://api.legiscan.com/'\n",
    "    assemble_url = f'https://api.legiscan.com/?key={api_key}&op=getSearch&state={state}&query={term.replace(\" \", \"+\")}'\n",
    "    assemble_params = {\n",
    "        'key': api_key,\n",
    "        'op': 'getSearch',\n",
    "        'state': state,\n",
    "        'query': term,\n",
    "    }\n",
    "    return requests.get(short_url, params=assemble_params).text\n",
    "\n",
    "json.loads(do_search('ME', '577')) # needs to be exact or the search can't find it :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea651e3-960d-4083-a8a4-eb49e5012167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/amy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/amy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/amy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('entitled', 'entitle'),\n",
       " ('relating', 'relate'),\n",
       " ('treatments', 'treatment'),\n",
       " ('amending', 'amend'),\n",
       " ('granting', 'grant'),\n",
       " ('courts', 'court'),\n",
       " ('children', 'child'),\n",
       " ('are', 'be'),\n",
       " ('are', 'be'),\n",
       " ('being', 'be'),\n",
       " ('subjected', 'subject'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('amending', 'amend'),\n",
       " ('requiring', 'require'),\n",
       " ('determining', 'determine'),\n",
       " ('is', 'be'),\n",
       " ('proceedings', 'proceeding'),\n",
       " ('amending', 'amend'),\n",
       " ('requiring', 'require'),\n",
       " ('courts', 'court'),\n",
       " ('as', 'a'),\n",
       " ('purposes', 'purpose'),\n",
       " ('determining', 'determine'),\n",
       " ('proceedings', 'proceeding'),\n",
       " ('prohibiting', 'prohibit'),\n",
       " ('treating', 'treat'),\n",
       " ('as', 'a'),\n",
       " ('circumstances', 'circumstance'),\n",
       " ('amending', 'amend'),\n",
       " ('defining', 'define'),\n",
       " ('purposes', 'purpose'),\n",
       " ('warrants', 'warrant'),\n",
       " ('proceedings', 'proceeding'),\n",
       " ('amending', 'amend'),\n",
       " ('providing', 'provide'),\n",
       " ('courts', 'court'),\n",
       " ('determinations', 'determination'),\n",
       " ('made', 'make'),\n",
       " ('circumstances', 'circumstance'),\n",
       " ('requiring', 'require'),\n",
       " ('creating', 'create'),\n",
       " ('prohibiting', 'prohibit'),\n",
       " ('entities', 'entity'),\n",
       " ('expending', 'expend'),\n",
       " ('funds', 'fund'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('amending', 'amend'),\n",
       " ('requiring', 'require'),\n",
       " ('licensed', 'license'),\n",
       " ('facilities', 'facility'),\n",
       " ('as', 'a'),\n",
       " ('specified', 'specify'),\n",
       " ('requiring', 'require'),\n",
       " ('procedures', 'procedure'),\n",
       " ('amending', 'amend'),\n",
       " ('defining', 'define'),\n",
       " ('terms', 'term'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('creating', 'create'),\n",
       " ('prohibiting', 'prohibit'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('patients', 'patient'),\n",
       " ('younger', 'young'),\n",
       " ('years', 'year'),\n",
       " ('providing', 'provide'),\n",
       " ('requiring', 'require'),\n",
       " ('rules', 'rule'),\n",
       " ('requiring', 'require'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('patients', 'patient'),\n",
       " ('older', 'old'),\n",
       " ('years', 'year'),\n",
       " ('prescribed', 'prescribe'),\n",
       " ('performed', 'perform'),\n",
       " ('providing', 'provide'),\n",
       " ('criteria', 'criterion'),\n",
       " ('providing', 'provide'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('defining', 'define'),\n",
       " ('providing', 'provide'),\n",
       " ('providing', 'provide'),\n",
       " ('penalties', 'penalty'),\n",
       " ('requiring', 'require'),\n",
       " ('rules', 'rule'),\n",
       " ('providing', 'provide'),\n",
       " ('rules', 'rule'),\n",
       " ('are', 'be'),\n",
       " ('replaced', 'replace'),\n",
       " ('rules', 'rule'),\n",
       " ('amending', 'amend'),\n",
       " ('requiring', 'require'),\n",
       " ('is', 'be'),\n",
       " ('arrested', 'arrest'),\n",
       " ('committing', 'commit'),\n",
       " ('attempting', 'attempt'),\n",
       " ('soliciting', 'solicit'),\n",
       " ('violations', 'violation'),\n",
       " ('related', 'relate'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('younger', 'young'),\n",
       " ('years', 'year'),\n",
       " ('amending', 'amend'),\n",
       " ('requiring', 'require'),\n",
       " ('registered', 'register'),\n",
       " ('physicians', 'physician'),\n",
       " ('offices', 'office'),\n",
       " ('requiring', 'require'),\n",
       " ('physicians', 'physician'),\n",
       " ('offices', 'office'),\n",
       " ('seeking', 'seek'),\n",
       " ('as', 'a'),\n",
       " ('providing', 'provide'),\n",
       " ('grounds', 'ground'),\n",
       " ('providing', 'provide'),\n",
       " ('providing', 'provide'),\n",
       " ('providing', 'provide'),\n",
       " ('is', 'be'),\n",
       " ('amended', 'amend'),\n",
       " ('has', 'have'),\n",
       " ('is', 'be'),\n",
       " ('has', 'have'),\n",
       " ('been', 'be'),\n",
       " ('abandoned', 'abandon'),\n",
       " ('is', 'be'),\n",
       " ('is', 'be'),\n",
       " ('subjected', 'subject'),\n",
       " ('threatened', 'threaten'),\n",
       " ('is', 'be'),\n",
       " ('is', 'be'),\n",
       " ('being', 'be'),\n",
       " ('subjected', 'subject'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('is', 'be'),\n",
       " ('amended', 'amend'),\n",
       " ('determining', 'determine'),\n",
       " ('is', 'be'),\n",
       " ('is', 'be'),\n",
       " ('parties', 'party'),\n",
       " ('factors', 'factor'),\n",
       " ('including', 'include'),\n",
       " ('has', 'have'),\n",
       " ('occurred', 'occur'),\n",
       " ('is', 'be'),\n",
       " ('parties', 'party'),\n",
       " ('has', 'have'),\n",
       " ('resided', 'reside'),\n",
       " ('circumstances', 'circumstance'),\n",
       " ('parties', 'party'),\n",
       " ('parties', 'party'),\n",
       " ('as', 'a'),\n",
       " ('required', 'require'),\n",
       " ('including', 'include'),\n",
       " ('procedures', 'procedure'),\n",
       " ('facts', 'fact'),\n",
       " ('issues', 'issue'),\n",
       " ('is', 'be'),\n",
       " ('parties', 'party'),\n",
       " ('is', 'be'),\n",
       " ('subjecting', 'subject'),\n",
       " ('is', 'be'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('is', 'be'),\n",
       " ('added', 'add'),\n",
       " ('declined', 'decline'),\n",
       " ('as', 'a'),\n",
       " ('attempting', 'attempt'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('as', 'a'),\n",
       " ('was', 'be'),\n",
       " ('protecting', 'protect'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('referenced', 'reference'),\n",
       " ('is', 'be'),\n",
       " ('was', 'be'),\n",
       " ('was', 'be'),\n",
       " ('being', 'be'),\n",
       " ('subjected', 'subject'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('is', 'be'),\n",
       " ('amended', 'amend'),\n",
       " ('seeking', 'seek'),\n",
       " ('is', 'be'),\n",
       " ('used', 'use'),\n",
       " ('includes', 'include'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('is', 'be'),\n",
       " ('amended', 'amend'),\n",
       " ('issued', 'issue'),\n",
       " ('enforces', 'enforce'),\n",
       " ('has', 'have'),\n",
       " ('been', 'be'),\n",
       " ('vacated', 'vacate'),\n",
       " ('stayed', 'stay'),\n",
       " ('modified', 'modify'),\n",
       " ('having', 'have'),\n",
       " ('has', 'have'),\n",
       " ('being', 'be'),\n",
       " ('subjected', 'subject'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('is', 'be'),\n",
       " ('created', 'create'),\n",
       " ('funds', 'fund'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('managing', 'manage'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('managed', 'manage'),\n",
       " ('providing', 'provide'),\n",
       " ('services', 'service'),\n",
       " ('funds', 'fund'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('subsections', 'subsection'),\n",
       " ('are', 'be'),\n",
       " ('as', 'a'),\n",
       " ('subsections', 'subsection'),\n",
       " ('is', 'be'),\n",
       " ('added', 'add'),\n",
       " ('subsections', 'subsection'),\n",
       " ('are', 'be'),\n",
       " ('amended', 'amend'),\n",
       " ('licensed', 'license'),\n",
       " ('signed', 'sign'),\n",
       " ('stating', 'state'),\n",
       " ('does', 'do'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('patients', 'patient'),\n",
       " ('younger', 'young'),\n",
       " ('years', 'year'),\n",
       " ('authorized', 'authorize'),\n",
       " ('does', 'do'),\n",
       " ('patients', 'patient'),\n",
       " ('providers', 'provider'),\n",
       " ('services', 'service'),\n",
       " ('licensed', 'license'),\n",
       " ('as', 'a'),\n",
       " ('requirements', 'requirement'),\n",
       " ('provided', 'provide'),\n",
       " ('fails', 'fail'),\n",
       " ('required', 'require'),\n",
       " ('licensed', 'license'),\n",
       " ('as', 'a'),\n",
       " ('as', 'a'),\n",
       " ('maintains', 'maintain'),\n",
       " ('services', 'service'),\n",
       " ('were', 'be'),\n",
       " ('beds', 'bed'),\n",
       " ('agreements', 'agreement'),\n",
       " ('services', 'service'),\n",
       " ('is', 'be'),\n",
       " ('violates', 'violate'),\n",
       " ('criteria', 'criterion'),\n",
       " ('rules', 'rule'),\n",
       " ('implementing', 'implement'),\n",
       " ('requirements', 'requirement'),\n",
       " ('days', 'day'),\n",
       " ('rendering', 'render'),\n",
       " ('its', 'it'),\n",
       " ('its', 'it'),\n",
       " ('proposed', 'propose'),\n",
       " ('days', 'day'),\n",
       " ('proceedings', 'proceeding'),\n",
       " ('challenging', 'challenge'),\n",
       " ('based', 'base'),\n",
       " ('facts', 'fact'),\n",
       " ('existing', 'exist'),\n",
       " ('proposed', 'propose'),\n",
       " ('hospitals', 'hospital'),\n",
       " ('based', 'base'),\n",
       " ('showing', 'show'),\n",
       " ('established', 'establish'),\n",
       " ('affected', 'affect'),\n",
       " ('are', 'be'),\n",
       " ('added', 'add'),\n",
       " ('used', 'use'),\n",
       " ('means', 'mean'),\n",
       " ('as', 'a'),\n",
       " ('based', 'base'),\n",
       " ('as', 'a'),\n",
       " ('indicated', 'indicate'),\n",
       " ('chromosomes', 'chromosome'),\n",
       " ('occurring', 'occur'),\n",
       " ('hormones', 'hormone'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('means', 'mean'),\n",
       " ('blockers', 'blocker'),\n",
       " ('attempting', 'attempt'),\n",
       " ('is', 'be'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('hormones', 'hormone'),\n",
       " ('antagonists', 'antagonist'),\n",
       " ('is', 'be'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('including', 'include'),\n",
       " ('is', 'be'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('does', 'do'),\n",
       " ('procedures', 'procedure'),\n",
       " ('individuals', 'individual'),\n",
       " ('born', 'bear'),\n",
       " ('including', 'include'),\n",
       " ('limited', 'limit'),\n",
       " ('procedures', 'procedure'),\n",
       " ('has', 'have'),\n",
       " ('been', 'be'),\n",
       " ('caused', 'cause'),\n",
       " ('exacerbated', 'exacerbate'),\n",
       " ('was', 'be'),\n",
       " ('performed', 'perform'),\n",
       " ('is', 'be'),\n",
       " ('covered', 'cover'),\n",
       " ('rights', 'right'),\n",
       " ('ss', 's'),\n",
       " ('procedures', 'procedure'),\n",
       " ('provided', 'provide'),\n",
       " ('certified', 'certify'),\n",
       " ('licensed', 'license'),\n",
       " ('is', 'be'),\n",
       " ('created', 'create'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('prohibitions', 'prohibition'),\n",
       " ('informed', 'inform'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('are', 'be'),\n",
       " ('prohibited', 'prohibit'),\n",
       " ('patients', 'patient'),\n",
       " ('younger', 'young'),\n",
       " ('years', 'year'),\n",
       " ('rules', 'rule'),\n",
       " ('pertaining', 'pertain'),\n",
       " ('standards', 'standard'),\n",
       " ('younger', 'young'),\n",
       " ('years', 'year'),\n",
       " ('treated', 'treat'),\n",
       " ('referenced', 'reference'),\n",
       " ('was', 'be'),\n",
       " ('commenced', 'commence'),\n",
       " ('is', 'be'),\n",
       " ('meeting', 'meet'),\n",
       " ('criteria', 'criterion'),\n",
       " ('treated', 'treat'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('according', 'accord'),\n",
       " ('rules', 'rule'),\n",
       " ('adopted', 'adopt'),\n",
       " ('rules', 'rule'),\n",
       " ('adopted', 'adopt'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('are', 'be'),\n",
       " ('administered', 'administer'),\n",
       " ('performed', 'perform'),\n",
       " ('patients', 'patient'),\n",
       " ('years', 'year'),\n",
       " ('older', 'old'),\n",
       " ('informed', 'inform'),\n",
       " ('writing', 'write'),\n",
       " ('forms', 'form'),\n",
       " ('approved', 'approve'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('is', 'be'),\n",
       " ('informed', 'inform'),\n",
       " ('is', 'be'),\n",
       " ('has', 'have'),\n",
       " ('risks', 'risk'),\n",
       " ('as', 'a'),\n",
       " ('approved', 'approve'),\n",
       " ('written', 'write'),\n",
       " ('is', 'be'),\n",
       " ('prescribed', 'prescribe'),\n",
       " ('performed', 'perform'),\n",
       " ('required', 'require'),\n",
       " ('provided', 'provide'),\n",
       " ('has', 'have'),\n",
       " ('been', 'be'),\n",
       " ('provided', 'provide'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('administered', 'administer'),\n",
       " ('performed', 'perform'),\n",
       " ('purposes', 'purpose'),\n",
       " ('is', 'be'),\n",
       " ('defined', 'define'),\n",
       " ('as', 'a'),\n",
       " ('licensed', 'license'),\n",
       " ('required', 'require'),\n",
       " ('does', 'do'),\n",
       " ('renewals', 'renewal'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('referenced', 'reference'),\n",
       " ('met', 'meet'),\n",
       " ('requirements', 'requirement'),\n",
       " ('is', 'be'),\n",
       " ('required', 'require'),\n",
       " ('prescribed', 'prescribe'),\n",
       " ('constitutes', 'constitute'),\n",
       " ('grounds', 'ground'),\n",
       " ('as', 'a'),\n",
       " ('commits', 'commit'),\n",
       " ('as', 'a'),\n",
       " ('provided', 'provide'),\n",
       " ('violates', 'violate'),\n",
       " ('commits', 'commit'),\n",
       " ('as', 'a'),\n",
       " ('provided', 'provide'),\n",
       " ('rules', 'rule'),\n",
       " ('rules', 'rule'),\n",
       " ('adopted', 'adopt'),\n",
       " ('are', 'be'),\n",
       " ('replaced', 'replace'),\n",
       " ('rules', 'rule'),\n",
       " ('adopted', 'adopt'),\n",
       " ('procedures', 'procedure'),\n",
       " ('paragraphs', 'paragraph'),\n",
       " ('are', 'be'),\n",
       " ('as', 'a'),\n",
       " ('paragraphs', 'paragraph'),\n",
       " ('is', 'be'),\n",
       " ('added', 'add'),\n",
       " ('practitioners', 'practitioner'),\n",
       " ('suspending', 'suspend'),\n",
       " ('is', 'be'),\n",
       " ('committing', 'commit'),\n",
       " ('attempting', 'attempt'),\n",
       " ('soliciting', 'solicit'),\n",
       " ('conspiring', 'conspire'),\n",
       " ('offenses', 'offense'),\n",
       " ('offenses', 'offense'),\n",
       " ('prescribing', 'prescribe'),\n",
       " ('performing', 'perform'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('younger', 'young'),\n",
       " ('years', 'year'),\n",
       " ('is', 'be'),\n",
       " ('amended', 'amend'),\n",
       " ('is', 'be'),\n",
       " ('demonstrating', 'demonstrate'),\n",
       " ('has', 'have'),\n",
       " ('met', 'meet'),\n",
       " ('continues', 'continue'),\n",
       " ('requirements', 'requirement'),\n",
       " ('physicians', 'physician'),\n",
       " ('registered', 'register'),\n",
       " ('requirements', 'requirement'),\n",
       " ('as', 'a'),\n",
       " ('registered', 'register'),\n",
       " ('does', 'do'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('patients', 'patient'),\n",
       " ('younger', 'young'),\n",
       " ('years', 'year'),\n",
       " ('does', 'do'),\n",
       " ('patients', 'patient'),\n",
       " ('providers', 'provider'),\n",
       " ('services', 'service'),\n",
       " ('seeking', 'seek'),\n",
       " ('signed', 'sign'),\n",
       " ('signed', 'sign'),\n",
       " ('is', 'be'),\n",
       " ('grounds', 'ground'),\n",
       " ('is', 'be'),\n",
       " ('amended', 'amend'),\n",
       " ('is', 'be'),\n",
       " ('demonstrating', 'demonstrate'),\n",
       " ('has', 'have'),\n",
       " ('met', 'meet'),\n",
       " ('continues', 'continue'),\n",
       " ('requirements', 'requirement'),\n",
       " ('physicians', 'physician'),\n",
       " ('registered', 'register'),\n",
       " ('requirements', 'requirement'),\n",
       " ('as', 'a'),\n",
       " ('registered', 'register'),\n",
       " ('does', 'do'),\n",
       " ('prescriptions', 'prescription'),\n",
       " ('procedures', 'procedure'),\n",
       " ('as', 'a'),\n",
       " ('defined', 'define'),\n",
       " ('patients', 'patient'),\n",
       " ('younger', 'young'),\n",
       " ('years', 'year'),\n",
       " ('does', 'do'),\n",
       " ('patients', 'patient'),\n",
       " ('providers', 'provider'),\n",
       " ('services', 'service'),\n",
       " ('seeking', 'seek'),\n",
       " ('signed', 'sign'),\n",
       " ('signed', 'sign'),\n",
       " ('is', 'be'),\n",
       " ('grounds', 'ground'),\n",
       " ('its', 'it'),\n",
       " ('is', 'be'),\n",
       " ('held', 'hold'),\n",
       " ('does', 'do'),\n",
       " ('provisions', 'provision'),\n",
       " ('applications', 'application'),\n",
       " ('given', 'give'),\n",
       " ('provisions', 'provision'),\n",
       " ('are', 'be'),\n",
       " ('is', 'be'),\n",
       " ('directed', 'direct'),\n",
       " ('occurs', 'occur'),\n",
       " ('becomes', 'become'),\n",
       " ('becoming', 'become')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from itertools import islice\n",
    "from nltk import download as nltk_download, pos_tag, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "\n",
    "nltk_download('punkt')\n",
    "nltk_download('averaged_perceptron_tagger')\n",
    "nltk_download('wordnet')\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "def extract_html_file(file_path: str):\n",
    "    soup = None\n",
    "    with open(file_path, 'r') as f:\n",
    "        soup = Soup(f, 'html.parser')\n",
    "\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "\n",
    "    text = soup.get_text()\n",
    "    tokens = (token for token in word_tokenize(text) if token not in string.punctuation)\n",
    "    return list(tokens)\n",
    "\n",
    "[(orig, lem) for orig, lem in ((word, lem.lemmatize(word, get_wordnet_pos(pos))) for word, pos in pos_tag(extract_html_file('bills/FL_S0254.html'))) if orig != lem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9694e04-952b-465b-81ab-2a9b8bf9f331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Florida', 'florida'),\n",
      " ('Senate', 'senat'),\n",
      " ('2023', '2023'),\n",
      " ('SB', 'sb'),\n",
      " ('254', '254'),\n",
      " ('By', 'by'),\n",
      " ('Senator', 'senat'),\n",
      " ('Yarborough', 'yarborough'),\n",
      " ('4-01859G-23', '4-01859g-23'),\n",
      " ('2023254__', '2023254__'),\n",
      " ('1', '1'),\n",
      " ('A', 'a'),\n",
      " ('bill', 'bill'),\n",
      " ('to', 'to'),\n",
      " ('be', 'be'),\n",
      " ('entitled', 'entitl'),\n",
      " ('2', '2'),\n",
      " ('An', 'an'),\n",
      " ('act', 'act'),\n",
      " ('relating', 'relat'),\n",
      " ('to', 'to'),\n",
      " ('treatments', 'treatment'),\n",
      " ('for', 'for'),\n",
      " ('sex', 'sex'),\n",
      " ('reassignment', 'reassign'),\n",
      " ('3', '3'),\n",
      " ('amending', 'amend'),\n",
      " ('s.', 's.'),\n",
      " ('61.517', '61.517'),\n",
      " ('F.S', 'f.'),\n",
      " ('granting', 'grant'),\n",
      " ('courts', 'court'),\n",
      " ('of', 'of'),\n",
      " ('this', 'thi'),\n",
      " ('4', '4'),\n",
      " ('state', 'state'),\n",
      " ('temporary', 'temporari'),\n",
      " ('emergency', 'emerg'),\n",
      " ('jurisdiction', 'jurisdict'),\n",
      " ('over', 'over'),\n",
      " ('children', 'children'),\n",
      " ('5', '5'),\n",
      " ('present', 'present'),\n",
      " ('in', 'in'),\n",
      " ('this', 'thi'),\n",
      " ('state', 'state'),\n",
      " ('if', 'if'),\n",
      " ('they', 'they'),\n",
      " ('are', 'are'),\n",
      " ('at', 'at'),\n",
      " ('risk', 'risk'),\n",
      " ('of', 'of'),\n",
      " ('or', 'or'),\n",
      " ('are', 'are'),\n",
      " ('6', '6'),\n",
      " ('being', 'be'),\n",
      " ('subjected', 'subject'),\n",
      " ('to', 'to'),\n",
      " ('the', 'the'),\n",
      " ('provision', 'provis'),\n",
      " ('of', 'of'),\n",
      " ('sex-reassignment', 'sex-reassign'),\n",
      " ('7', '7'),\n",
      " ('prescriptions', 'prescript'),\n",
      " ('or', 'or'),\n",
      " ('procedures', 'procedur'),\n",
      " ('amending', 'amend'),\n",
      " ('s.', 's.'),\n",
      " ('61.520', '61.520'),\n",
      " ('F.S', 'f.'),\n",
      " ('8', '8'),\n",
      " ('requiring', 'requir'),\n",
      " ('the', 'the'),\n",
      " ('court', 'court'),\n",
      " ('to', 'to'),\n",
      " ('consider', 'consid'),\n",
      " ('certain', 'certain'),\n",
      " ('information', 'inform'),\n",
      " ('9', '9'),\n",
      " ('when', 'when'),\n",
      " ('determining', 'determin'),\n",
      " ('whether', 'whether'),\n",
      " ('the', 'the'),\n",
      " ('court', 'court'),\n",
      " ('of', 'of'),\n",
      " ('another', 'anoth'),\n",
      " ('10', '10'),\n",
      " ('jurisdiction', 'jurisdict'),\n",
      " ('is', 'is'),\n",
      " ('the', 'the'),\n",
      " ('more', 'more'),\n",
      " ('appropriate', 'appropri'),\n",
      " ('or', 'or'),\n",
      " ('convenient', 'conveni'),\n",
      " ('11', '11'),\n",
      " ('forum', 'forum'),\n",
      " ('for', 'for'),\n",
      " ('child', 'child'),\n",
      " ('custody', 'custodi'),\n",
      " ('determination', 'determin')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/amy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from itertools import islice\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pprint import pprint\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def extract_html_file(file_path: str):\n",
    "    soup = None\n",
    "    with open(file_path, 'r') as f:\n",
    "        soup = Soup(f, 'html.parser')\n",
    "\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "\n",
    "    text = soup.get_text()\n",
    "    tokens = (token for token in word_tokenize(text) if token not in string.punctuation)\n",
    "    return tokens\n",
    "    # break into lines and remove leading and trailing space on each\n",
    "    #lines = (line.strip() for line in text.splitlines())\n",
    "    # break multi-headlines into a line each\n",
    "    #chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    # drop blank lines\n",
    "    #text = \"\\n\".join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "    #return text\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "pprint([(word, ps.stem(word)) for word in islice(extract_html_file('bills/FL_S0254.html'), 100)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c39bdf-ec41-4f0e-b4c2-dd8633109951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2658134"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import base64\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "filename = 'tmp/bill_meta_TX_HB1532.json'\n",
    "\n",
    "result = None\n",
    "with open(filename, 'r') as f:\n",
    "    result = json.load(f)['bill']\n",
    "\n",
    "extra = result['texts'][0].copy()\n",
    "extra['date'] = '2023-01-01'\n",
    "result['texts'].append(extra)\n",
    "# pprint(result['texts'])\n",
    "s = sorted(result['texts'], key=lambda x: x['date'], reverse=True)\n",
    "doc_id = result['texts'][0]['doc_id']\n",
    "doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b77109c-79ed-4fd1-a625-bb7b138dfcde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m sample\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 23\u001b[0m     local_filename \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbill\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m             row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;241m*\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbillId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     30\u001b[0m         ])\n\u001b[1;32m     31\u001b[0m     ) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_filename):\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from legiscan import legiscan_api\n",
    "import pandas as pd\n",
    "\n",
    "raw = pd.read_json('tracktranslegislation.json')\n",
    "sample = raw.sample(n=3, random_state=1234)\n",
    "\n",
    "@legiscan_api\n",
    "def get_bill_meta(legiscan_bill_id: str, api_key: str):\n",
    "    assembled_url = f'https://api.legiscan.com/?key={api_key}&op=getBill&id={legiscan_bill_id}'\n",
    "    resp = requests.get(assembled_url)\n",
    "\n",
    "    if resp.ok:\n",
    "        parsed = json.loads(resp.text)\n",
    "        if parsed['status'] == 'ERROR':\n",
    "            print(parsed['alert']['message'])\n",
    "            return None\n",
    "        return resp\n",
    "    else:\n",
    "        print(resp.status_code)\n",
    "        return None\n",
    "    \n",
    "for idx, row in sample.iterrows():\n",
    "    local_filename = os.path.join(\n",
    "        'tmp',\n",
    "        '_'.join([\n",
    "            'bill',\n",
    "            'meta',\n",
    "            row[\"state\"],\n",
    "            *row[\"billId\"].split(' '),\n",
    "        ])\n",
    "    ) + '.json'\n",
    "    \n",
    "    if os.path.exists(local_filename):\n",
    "        print(f'skipping {local_filename}')\n",
    "        continue\n",
    "    \n",
    "    resp = None\n",
    "    resp = get_bill_meta(row['legiscanId'])\n",
    "    if not resp:\n",
    "        print(f'Could not download {local_filename}')\n",
    "        continue\n",
    "    \n",
    "    print(f'got {local_filename}')\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        f.write(resp.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180872e-a65b-4289-bb41-8cff73e0dc0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw = pd.read_json('tracktranslegislation.json')\n",
    "sample = raw.sample(n=3, random_state=1234)\n",
    "sample\n",
    "\n",
    "# 7 has wrong legiscanId, should be 2721785 i think\n",
    "# 44 also has wrong legiscanId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1612b-bdd2-4c19-9419-6280b93d021f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "filename = 'bills/TX_HB1532'\n",
    "\n",
    "result = None\n",
    "with open(filename, 'r') as f:\n",
    "    result = json.load(f)['text']\n",
    "\n",
    "doc = result['doc']\n",
    "extension = result['mime'].split('/')[-1]\n",
    "new_filename = '.'.join([filename, extension])\n",
    "\n",
    "with open(new_filename, 'wb') as f:\n",
    "    f.write(base64.b64decode(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fff686-1f74-4e15-a9a1-19d27706da9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from legiscan import legiscan_api\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import requests\n",
    "\n",
    "@legiscan_api\n",
    "def get_bill_text(legiscan_bill_id: str, api_key: str):\n",
    "    # https://api.legiscan.com/?key=5f61f50916512f9f21500f38877c22f7&op=getBillText&id=2736883\n",
    "    assembled_url = f'https://api.legiscan.com/?key={api_key}&op=getBillText&id={legiscan_bill_id}'\n",
    "    resp = requests.get(assembled_url)\n",
    "\n",
    "    if resp.ok:\n",
    "        parsed = json.loads(resp.text)\n",
    "        if parsed['status'] == 'ERROR':\n",
    "            print(parsed['alert']['message'])\n",
    "            return None\n",
    "        return resp\n",
    "    else:\n",
    "        print(resp.status_code)\n",
    "        return None\n",
    "\n",
    "raw = pd.read_json('tracktranslegislation.json')\n",
    "sample = raw.sample(n=3, random_state=1234)\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    local_filename = os.path.join(\n",
    "        'bills',\n",
    "        '_'.join([\n",
    "            row[\"state\"],\n",
    "            *row[\"billId\"].split(' '),\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(local_filename):\n",
    "        print(f'skipping {local_filename}')\n",
    "    \n",
    "    resp = get_bill_text(row['legiscanId'])\n",
    "    if not resp:\n",
    "        print(f'Could not download {local_filename}')\n",
    "        continue\n",
    "    \n",
    "    with open(local_filename, 'wb') as f:\n",
    "        f.write(resp.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77354a2b-b3bc-4f96-bf92-2dbc7a80279e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from legiscan import legiscan_api\n",
    "import os\n",
    "\n",
    "@legiscan_api\n",
    "def sample_api_action(api_key: str):\n",
    "    print(f'api key is {api_key}')\n",
    "\n",
    "@legiscan_api\n",
    "def get_bill_text(legiscan_bill_id: str, api_key: str):\n",
    "    # https://api.legiscan.com/?key=5f61f50916512f9f21500f38877c22f7&op=getBillText&id=2736883\n",
    "    assembled_url = f'https://api.legiscan.com/?key={api_key}&op=getBillText&id={legiscan_bill_id}'\n",
    "    print(assembled_url)\n",
    "    \n",
    "sample_api_action(api_key='foo')\n",
    "\n",
    "\n",
    "get_bill_text('12345')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec9fc5-e6b0-4f04-a00e-097f4097fbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "host = 'https://www.house.mo.gov'\n",
    "# url = f'{host}/BillContent.aspx?bill=HB1258&year=2023&code=R'\n",
    "url = urllib.parse.urljoin(host, 'BillContent.aspx?bill=HB1258&year=2023&code=R')\n",
    "page = requests.get(url)\n",
    "\n",
    "# print(page.text)\n",
    "soup = BeautifulSoup(page.content)\n",
    "urllib.parse.urljoin(\n",
    "    host, \n",
    "    soup.find_all(class_='textType')[0].find('a')['href'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0164bd3-1c4f-4ebc-b7a4-5eaa81af950b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Optional\n",
    "import urllib.parse\n",
    "\n",
    "def test_url(url: str, parent_id: str, anchor_index: int):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    container = soup.find(id=parent_id)\n",
    "    if not container:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return container.find_all('a')[anchor_index]['href']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def prepare_url(relative_url: Optional[str]):\n",
    "    if not relative_url:\n",
    "        return 'NO RESULT'\n",
    "    \n",
    "    return urllib.parse.urljoin('https://legiscan.com/', relative_url)\n",
    "\n",
    "def process_as_bill(frame) -> Optional[str]:\n",
    "    return process_bill_link(frame['billLink'])\n",
    "\n",
    "def process_bill_link(url: str) -> Optional[str]:\n",
    "    print(url)\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='bill-last-action')\n",
    "        anchors = container.find_all('a')\n",
    "        href = anchors[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def process_as_text(frame) -> Optional[str]:\n",
    "    state = frame['state']\n",
    "    bill_id = frame['billId'].replace(' ', '')\n",
    "    year = row['billLink'].split('/')[-1] # don't trust statusDate\n",
    "    text_link = f'https://legiscan.com/{state}/text/{bill_id}/{year}'\n",
    "    return process_text_link(text_link)\n",
    "\n",
    "def process_text_link(url: str) -> Optional[str]:\n",
    "    print(url)\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='gaits-wrapper')\n",
    "        href = container.find_all('a')[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def process_as_draft(frame) -> Optional[str]:\n",
    "    state = frame['state']\n",
    "    bill_id = frame['billId'].replace(' ', '')\n",
    "    year = row['billLink'].split('/')[-1] # don't trust statusDate\n",
    "    text_link = f'https://legiscan.com/{state}/drafts/{bill_id}/{year}'\n",
    "    return process_text_link(text_link)\n",
    "    \n",
    "def process_draft_link(url: str) -> Optional[str]:\n",
    "    print(url)\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='gaits-wrapper')\n",
    "        href = container.find_all('a')[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "raw = pd.read_json('tracktranslegislation.json')\n",
    "sample = raw.copy()\n",
    "# sample = raw.sample(n=20, random_state=2)\n",
    "# sample = raw.loc[raw.state == 'AR']\n",
    "# sample = raw.loc[0:20]\n",
    "# print(sample)\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    continue\n",
    "    bill_id = ' '.join([row['state'], row['billId']])\n",
    "#    year = row['billLink'].split('/')[-1]\n",
    "    \n",
    "#    bill_link = row['billLink']\n",
    "#    draft_link = f'https://legiscan.com/{row[\"state\"]}/drafts/{row[\"billId\"].replace(\" \", \"\")}/{year}' # https://legiscan.com/AZ/drafts/HB2517/2023\n",
    "#    text_link = f'https://legiscan.com/{row[\"state\"]}/text/{row[\"billId\"].replace(\" \", \"\")}/{year}'\n",
    "#    comments_link = f'https://legiscan.com/{row[\"state\"]}/comments/{row[\"billId\"].replace(\" \", \"\")}/{year}'\n",
    "    \n",
    "    searches = [\n",
    "        process_as_bill,\n",
    "        process_as_text,\n",
    "    ]\n",
    "\n",
    "    print(f'{bill_id}')\n",
    "    for search in searches:\n",
    "        print(search(row))\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44ff23-fac6-4b06-acae-4fcaa34bdd48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://legiscan.com/TX/comments/HB1029/2023\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from typing import Optional\n",
    "import urllib.parse\n",
    "\n",
    "def process_as_bill(frame) -> Optional[str]:\n",
    "    return process_bill_link(frame['billLink'])\n",
    "\n",
    "def process_bill_link(url: str) -> Optional[str]:\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='bill-last-action')\n",
    "        anchors = container.find_all('a')\n",
    "        href = anchors[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def process_as_text(frame) -> Optional[str]:\n",
    "    state = frame['state']\n",
    "    bill_id = frame['billId'].replace(' ', '')\n",
    "    year = row['billLink'].split('/')[-1] # don't trust statusDate\n",
    "    text_link = f'https://legiscan.com/{state}/text/{bill_id}/{year}'\n",
    "    return process_text_link(text_link)\n",
    "\n",
    "def process_text_link(url: str) -> Optional[str]:\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='gaits-wrapper')\n",
    "        href = container.find_all('a')[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def process_as_draft(frame) -> Optional[str]:\n",
    "    state = frame['state']\n",
    "    bill_id = frame['billId'].replace(' ', '')\n",
    "    year = row['billLink'].split('/')[-1] # don't trust statusDate\n",
    "    text_link = f'https://legiscan.com/{state}/drafts/{bill_id}/{year}'\n",
    "    return process_text_link(text_link)\n",
    "    \n",
    "def process_draft_link(url: str) -> Optional[str]:\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='gaits-wrapper')\n",
    "        href = container.find_all('a')[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    \n",
    "#text_link = 'https://legiscan.com/TX/text/HB3147/2023'\n",
    "#print(text_link)\n",
    "#print(process_text_link(text_link))\n",
    "\n",
    "#bill_link = 'https://legiscan.com/TX/bill/HB976/2023'\n",
    "#print(bill_link)\n",
    "#print(process_bill_link(bill_link))\n",
    "#print(process_as_bill(sample.loc[303]))\n",
    "\n",
    "print(process_as_bill(raw.loc[251]))\n",
    "print(process_as_text(raw.loc[251]))\n",
    "print(process_as_draft(raw.loc[251]))\n",
    "\n",
    "#host = 'https://www.house.mo.gov'\n",
    "# url = f'{host}/BillContent.aspx?bill=HB1258&year=2023&code=R'\n",
    "#url = 'https://legiscan.com/SD/text/HB1080/2023' #urllib.parse.urljoin(host, 'BillContent.aspx?bill=HB1258&year=2023&code=R')\n",
    "#page = requests.get(url)\n",
    "\n",
    "# print(page.text)\n",
    "#soup = BeautifulSoup(page.content)\n",
    "#container = soup.find(id='gaits-wrapper')\n",
    "#pprint(container.find_all('a'))\n",
    "#urllib.parse.urljoin(\n",
    "#    host, \n",
    "#    soup.find_all(class_='textType')[0].find('a')['href'],\n",
    "#)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
