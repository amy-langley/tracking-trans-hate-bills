{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbe1612b-bdd2-4c19-9419-6280b93d021f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "filename = 'bills/IA_HF8'\n",
    "\n",
    "result = None\n",
    "with open(filename, 'r') as f:\n",
    "    result = json.load(f)['text']\n",
    "\n",
    "doc = result['doc']\n",
    "# result['doc'] = base64.b64decode(doc).decode('ascii')[0:100]\n",
    "extension = result['mime'].split('/')[-1]\n",
    "new_filename = '.'.join([filename, extension])\n",
    "\n",
    "with open(new_filename, 'wb') as f:\n",
    "    f.write(base64.b64decode(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83fff686-1f74-4e15-a9a1-19d27706da9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from legiscan import legiscan_api\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import requests\n",
    "\n",
    "@legiscan_api\n",
    "def get_bill_text(legiscan_bill_id: str, api_key: str):\n",
    "    # https://api.legiscan.com/?key=5f61f50916512f9f21500f38877c22f7&op=getBillText&id=2736883\n",
    "    assembled_url = f'https://api.legiscan.com/?key={api_key}&op=getBillText&id={legiscan_bill_id}'\n",
    "    resp = requests.get(assembled_url)\n",
    "\n",
    "    if resp.ok:\n",
    "        parsed = json.loads(resp.text)\n",
    "        if parsed['status'] == 'ERROR':\n",
    "            print(parsed['alert']['message'])\n",
    "            return None\n",
    "        return resp\n",
    "    else:\n",
    "        print(resp.status_code)\n",
    "        return None\n",
    "\n",
    "raw = pd.read_json('tracktranslegislation.json')\n",
    "sample = raw.sample(n=3, random_state=1234)\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    local_filename = os.path.join(\n",
    "        'bills',\n",
    "        '_'.join([\n",
    "            row[\"state\"],\n",
    "            *row[\"billId\"].split(' '),\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(local_filename):\n",
    "        print(f'skipping {local_filename}')\n",
    "    \n",
    "    resp = get_bill_text(row['legiscanId'])\n",
    "    if not resp:\n",
    "        print(f'Could not download {local_filename}')\n",
    "        continue\n",
    "    \n",
    "    with open(local_filename, 'wb') as f:\n",
    "        f.write(resp.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77354a2b-b3bc-4f96-bf92-2dbc7a80279e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api key is foo\n",
      "https://api.legiscan.com/?key=5f61f50916512f9f21500f38877c22f7&op=getBillText&id=12345\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "from legiscan import legiscan_api\n",
    "import os\n",
    "\n",
    "@legiscan_api\n",
    "def sample_api_action(api_key: str):\n",
    "    print(f'api key is {api_key}')\n",
    "\n",
    "@legiscan_api\n",
    "def get_bill_text(legiscan_bill_id: str, api_key: str):\n",
    "    # https://api.legiscan.com/?key=5f61f50916512f9f21500f38877c22f7&op=getBillText&id=2736883\n",
    "    assembled_url = f'https://api.legiscan.com/?key={api_key}&op=getBillText&id={legiscan_bill_id}'\n",
    "    print(assembled_url)\n",
    "    \n",
    "sample_api_action(api_key='foo')\n",
    "\n",
    "\n",
    "get_bill_text('12345')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec9fc5-e6b0-4f04-a00e-097f4097fbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "host = 'https://www.house.mo.gov'\n",
    "# url = f'{host}/BillContent.aspx?bill=HB1258&year=2023&code=R'\n",
    "url = urllib.parse.urljoin(host, 'BillContent.aspx?bill=HB1258&year=2023&code=R')\n",
    "page = requests.get(url)\n",
    "\n",
    "# print(page.text)\n",
    "soup = BeautifulSoup(page.content)\n",
    "urllib.parse.urljoin(\n",
    "    host, \n",
    "    soup.find_all(class_='textType')[0].find('a')['href'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0164bd3-1c4f-4ebc-b7a4-5eaa81af950b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Optional\n",
    "import urllib.parse\n",
    "\n",
    "def test_url(url: str, parent_id: str, anchor_index: int):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    container = soup.find(id=parent_id)\n",
    "    if not container:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return container.find_all('a')[anchor_index]['href']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def prepare_url(relative_url: Optional[str]):\n",
    "    if not relative_url:\n",
    "        return 'NO RESULT'\n",
    "    \n",
    "    return urllib.parse.urljoin('https://legiscan.com/', relative_url)\n",
    "\n",
    "def process_as_bill(frame) -> Optional[str]:\n",
    "    return process_bill_link(frame['billLink'])\n",
    "\n",
    "def process_bill_link(url: str) -> Optional[str]:\n",
    "    print(url)\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='bill-last-action')\n",
    "        anchors = container.find_all('a')\n",
    "        href = anchors[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def process_as_text(frame) -> Optional[str]:\n",
    "    state = frame['state']\n",
    "    bill_id = frame['billId'].replace(' ', '')\n",
    "    year = row['billLink'].split('/')[-1] # don't trust statusDate\n",
    "    text_link = f'https://legiscan.com/{state}/text/{bill_id}/{year}'\n",
    "    return process_text_link(text_link)\n",
    "\n",
    "def process_text_link(url: str) -> Optional[str]:\n",
    "    print(url)\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='gaits-wrapper')\n",
    "        href = container.find_all('a')[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def process_as_draft(frame) -> Optional[str]:\n",
    "    state = frame['state']\n",
    "    bill_id = frame['billId'].replace(' ', '')\n",
    "    year = row['billLink'].split('/')[-1] # don't trust statusDate\n",
    "    text_link = f'https://legiscan.com/{state}/drafts/{bill_id}/{year}'\n",
    "    return process_text_link(text_link)\n",
    "    \n",
    "def process_draft_link(url: str) -> Optional[str]:\n",
    "    print(url)\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='gaits-wrapper')\n",
    "        href = container.find_all('a')[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "raw = pd.read_json('tracktranslegislation.json')\n",
    "sample = raw.copy()\n",
    "# sample = raw.sample(n=20, random_state=2)\n",
    "# sample = raw.loc[raw.state == 'AR']\n",
    "# sample = raw.loc[0:20]\n",
    "# print(sample)\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    continue\n",
    "    bill_id = ' '.join([row['state'], row['billId']])\n",
    "#    year = row['billLink'].split('/')[-1]\n",
    "    \n",
    "#    bill_link = row['billLink']\n",
    "#    draft_link = f'https://legiscan.com/{row[\"state\"]}/drafts/{row[\"billId\"].replace(\" \", \"\")}/{year}' # https://legiscan.com/AZ/drafts/HB2517/2023\n",
    "#    text_link = f'https://legiscan.com/{row[\"state\"]}/text/{row[\"billId\"].replace(\" \", \"\")}/{year}'\n",
    "#    comments_link = f'https://legiscan.com/{row[\"state\"]}/comments/{row[\"billId\"].replace(\" \", \"\")}/{year}'\n",
    "    \n",
    "    searches = [\n",
    "        process_as_bill,\n",
    "        process_as_text,\n",
    "    ]\n",
    "\n",
    "    print(f'{bill_id}')\n",
    "    for search in searches:\n",
    "        print(search(row))\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44ff23-fac6-4b06-acae-4fcaa34bdd48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://legiscan.com/TX/comments/HB1029/2023\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from typing import Optional\n",
    "import urllib.parse\n",
    "\n",
    "def process_as_bill(frame) -> Optional[str]:\n",
    "    return process_bill_link(frame['billLink'])\n",
    "\n",
    "def process_bill_link(url: str) -> Optional[str]:\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='bill-last-action')\n",
    "        anchors = container.find_all('a')\n",
    "        href = anchors[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def process_as_text(frame) -> Optional[str]:\n",
    "    state = frame['state']\n",
    "    bill_id = frame['billId'].replace(' ', '')\n",
    "    year = row['billLink'].split('/')[-1] # don't trust statusDate\n",
    "    text_link = f'https://legiscan.com/{state}/text/{bill_id}/{year}'\n",
    "    return process_text_link(text_link)\n",
    "\n",
    "def process_text_link(url: str) -> Optional[str]:\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='gaits-wrapper')\n",
    "        href = container.find_all('a')[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def process_as_draft(frame) -> Optional[str]:\n",
    "    state = frame['state']\n",
    "    bill_id = frame['billId'].replace(' ', '')\n",
    "    year = row['billLink'].split('/')[-1] # don't trust statusDate\n",
    "    text_link = f'https://legiscan.com/{state}/drafts/{bill_id}/{year}'\n",
    "    return process_text_link(text_link)\n",
    "    \n",
    "def process_draft_link(url: str) -> Optional[str]:\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        container = soup.find(id='gaits-wrapper')\n",
    "        href = container.find_all('a')[-1]['href']\n",
    "        return urllib.parse.urljoin('https://legiscan.com', href)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    \n",
    "#text_link = 'https://legiscan.com/TX/text/HB3147/2023'\n",
    "#print(text_link)\n",
    "#print(process_text_link(text_link))\n",
    "\n",
    "#bill_link = 'https://legiscan.com/TX/bill/HB976/2023'\n",
    "#print(bill_link)\n",
    "#print(process_bill_link(bill_link))\n",
    "#print(process_as_bill(sample.loc[303]))\n",
    "\n",
    "print(process_as_bill(raw.loc[251]))\n",
    "print(process_as_text(raw.loc[251]))\n",
    "print(process_as_draft(raw.loc[251]))\n",
    "\n",
    "#host = 'https://www.house.mo.gov'\n",
    "# url = f'{host}/BillContent.aspx?bill=HB1258&year=2023&code=R'\n",
    "#url = 'https://legiscan.com/SD/text/HB1080/2023' #urllib.parse.urljoin(host, 'BillContent.aspx?bill=HB1258&year=2023&code=R')\n",
    "#page = requests.get(url)\n",
    "\n",
    "# print(page.text)\n",
    "#soup = BeautifulSoup(page.content)\n",
    "#container = soup.find(id='gaits-wrapper')\n",
    "#pprint(container.find_all('a'))\n",
    "#urllib.parse.urljoin(\n",
    "#    host, \n",
    "#    soup.find_all(class_='textType')[0].find('a')['href'],\n",
    "#)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
